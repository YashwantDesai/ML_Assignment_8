{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c27a818",
   "metadata": {},
   "source": [
    "# Yashwant Desai â€“  ML_Assignment_8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d5c8be",
   "metadata": {},
   "source": [
    "# 1. What exactly is a feature? Give an example to illustrate your point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85d34fe",
   "metadata": {},
   "source": [
    "A feature in the context of machine learning, is an individual measurable property or characteristic of the data that is used to make predictions or classify data points. \n",
    "\n",
    "For example in a dataset of houses for sale features could include the number of bedrooms, square footage, location, and price."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f63e78",
   "metadata": {},
   "source": [
    "# 2. What are the various circumstances in which feature construction is required?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dff4bae",
   "metadata": {},
   "source": [
    "Feature construction is required in the following circumstances.\n",
    "\n",
    "o When the existing features are insufficient for solving a specific machine learning problem.\n",
    "\n",
    "o When you want to capture complex relationships between features.\n",
    "\n",
    "o When you need to reduce dimensionality to improve model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ca9c7e",
   "metadata": {},
   "source": [
    "# 3. Describe how nominal variables are encoded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b24413",
   "metadata": {},
   "source": [
    "Nominal variables are categorical variables that have no inherent order. They can be encoded using one-hot encoding where each category is converted into a binary feature (0 or 1). \n",
    "\n",
    "For example if the nominal variable is \"Color\" with categories {Red, Blue, Green} it would be encoded as three binary columns: Red, Blue, Green."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ef78ac",
   "metadata": {},
   "source": [
    "# 4. Describe how numeric features are converted to categorical features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e92ddae",
   "metadata": {},
   "source": [
    "Numeric features can be converted to categorical features by binning or discretizing the data. This involves dividing the range of numeric values into bins or categories. \n",
    "\n",
    "For example you could convert age into age groups like \"Child,\" \"Adult,\" and \"Senior\" based on predefined age ranges."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8cb361",
   "metadata": {},
   "source": [
    "# 5. Describe the feature selection wrapper approach. State the advantages and disadvantages of this approach?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d6ae1b",
   "metadata": {},
   "source": [
    "The feature selection wrapper approach involves using a machine learning model to evaluate subsets of features and select the best combination based on performance. \n",
    "\n",
    "Advantages include feature interactions being considered but it can be computationally expensive. \n",
    "\n",
    "Disadvantages include overfitting to the specific model and potential high computational cost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fe2f9e",
   "metadata": {},
   "source": [
    "# 6. When is a feature considered irrelevant? What can be said to quantify it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e7bf7b",
   "metadata": {},
   "source": [
    "A feature is considered irrelevant when it does not contribute meaningful information to the predictive task. \n",
    "\n",
    "It can be quantified using techniques like feature importance scores, correlation coefficients or statistical tests to assess its impact on the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd12463",
   "metadata": {},
   "source": [
    "# 7. When is a function considered redundant? What criteria are used to identify features that could be redundant?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2d9166",
   "metadata": {},
   "source": [
    "A function is considered redundant when it provides the same or highly correlated information as another feature. \n",
    "\n",
    "Criteria for identifying redundancy include high correlation coefficients, feature importance scores, and the ability to predict the same target variable as another feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae1b87f",
   "metadata": {},
   "source": [
    "# 8. What are the various distance measurements used to determine feature similarity?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf8c275",
   "metadata": {},
   "source": [
    "Various distance measurements include Euclidean distance, Manhattan distance, Cosine similarity, Jaccard similarity, and Mahalanobis distance, among others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffa7e4c",
   "metadata": {},
   "source": [
    "# 9. State difference between Euclidean and Manhattan distances?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347d4811",
   "metadata": {},
   "source": [
    "The main difference between Euclidean and Manhattan distances is the way they measure distance between points in space. \n",
    "\n",
    "Euclidean distance calculates the straight-line (shortest) distance between two points while Manhattan distance calculates the distance as the sum of the absolute differences between their coordinates along each axis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9c795a",
   "metadata": {},
   "source": [
    "# 10. Distinguish between feature transformation and feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4b2e92",
   "metadata": {},
   "source": [
    "Feature transformation involves changing the representation of existing features such as scaling or reducing dimensionality while keeping all features. \n",
    "\n",
    "Feature selection involves choosing a subset of the most relevant features and discarding the rest to simplify the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a581da5a",
   "metadata": {},
   "source": [
    "# 11. Make brief notes on any two of the following:   1.SVD (Standard Variable Diameter Diameter)      2. Collection of features using a hybrid approach     3. The width of the silhouette     4. Receiver operating characteristic curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d40e3b",
   "metadata": {},
   "source": [
    "SVD (Standard Variable Diameter): SVD is not a standard term in machine learning. It might be a misunderstanding or typo. Singular Value Decomposition (SVD) is a matrix factorization technique often used in dimensionality reduction and recommendation systems.\n",
    "\n",
    "Collection of features using a hybrid approach: A hybrid approach involves combining multiple methods for feature selection or extraction to create a more robust feature set. It may use both filter and wrapper methods or combine domain knowledge with automated techniques to select or engineer features.\n",
    "\n",
    "The width of the silhouette: The silhouette width is a measure of how similar an object is to its cluster (cohesion) compared to other clusters (separation). It quantifies the quality of a clustering solution, with a higher silhouette width indicating well-separated clusters.\n",
    "\n",
    "Receiver Operating Characteristic (ROC) Curve: The ROC curve is a graphical representation of a binary classification model's performance. It plots the trade-off between true positive rate and false positive rate as the discrimination threshold is varied. The area under the ROC curve (AUC) is a common metric for evaluating model performance with a higher AUC indicating better classification accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572463c3",
   "metadata": {},
   "source": [
    "# Done all 11 questions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04469f9",
   "metadata": {},
   "source": [
    "# Regards,Yashwant"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
